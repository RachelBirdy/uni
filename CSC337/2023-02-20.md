# Interactions
Vis designers face limitations:
•Human limits (Time, memory, attention)
•Display limits (screen space, pixel density)
•Computational limits (Time and memory)

Interactions allow trade-offs between these resources.

## Some guidelines
### Looking is better than interacting
Interactions cost users time. For example:
• Moving and fixating eyes: 220-285ms
• Mouse click: 0.2s
• Kepress on a keyboard: 0.35s
• Mouse movement: 1.1s

More precise interaction, such as moving the mouse to a very small target, also takes longer than more crude interactions. If the target is further away, the movement takes longer, and if the target is small the user will often overshoot or undershoot and have to make additional, corrective mouse movements.

Another issue with interacting is that the user may just, not interact. For example, if a visualization includes a button to switch between views of the data, very few users may actually press that button.

### Repsond first, complete later
If two elements of an interaction take longer than 0.1s, the perception of cause/effect starts to break. The example in the slides is a video that shows a ball moving into frame, colliding with another ball, and the second ball moving out of frame, with different delays between when the second ball is hit, and when it starts moving. Though I'd imagine this also applies to UI element responsiveness?

In interaction takes longer than 1s, the users flow of thought is interrupted and the system feels non responsive.

If the interaction takes longer than 10s, the user shifts their attention away from the task.

Therefore, if you have some visualization that is computationally intensive, respond first, and complete the task later. Give the user some instantaneous indicator that the system is now working.

One way of doing this is the hourglass icon a pc mouse changes to.
Another way is to render rough output before filling in details, like progressive rendering of a jpeg.

### Choose resolution over immersion
• A <b>pixel</b> is the smallest independ hardware graphic element
• <b>Pixel density</b> is the pixel count per area, typically dots per inch (dpi)
• <b>Screen resolution</b> is the number of pixels available in each dimension of a screen, for example 1280x720
• <b>Screen size</b> is the physical height and width of the screen
• <b>Immersion</b> is the perception of being physically present in a non-physical world

These elements are different across different platforms. For instance, augmented reality has high immersion but low resolution.

<b>Whenever you have to choose between resolution and immersion, choose resolution.</b>

### Match input capabilities to interactions
Different hardware allows different input. For instance, a mouse allows you to hover over an element but a touch screen doesn't have an equivalent hover state.

A mouse is typically present with a keyboard, so the user can use keyboard modifiers for additional input on mouse actions.

Touch screens on the other hand, may have multi touch gestures that allow more interaction.

Less common is pen intput. Pens can allow all of the states of mouse and touch screens.

### Not discoverable = not interactive
If a chart has a pan/zoom function but the user doesn't know that the chart has a pan/zoom function, they will not use it. This makes the display functionally non-interactive. Therefore it's important to use standard user interface widgets like buttons and sliders.

However, these widgets occupy screen space so be sure to use them sparingly or not more than necessary.

The same interaction can also be provided via multiple methods. For instance, as well as an on screen slider, zoom could be achieved with mouse wheen scrolling and with the ctrl + key combo. Like redundant encoding of data, this is redundant interaction.

You can also provide a tutorial for the user to illustrate features.

## Common interaction techniques for visualization
### Change over time
Pros:
This saves screen space. 

Cons:
The user needs to remember the state before/after. This increases cognitive load.

This can occur with or without user input, and many things can be changed over time such as order, alignment, parameters, encoding, and the data ro the method to derive data.

Examples of this are presented in the lecture recording

### Changing order
This can be used to reveal correlations. For instance, by ordering the data using one attribute you may be able to see some ordering emerge in another attribute.

### Changing alignment
In a segmented bar graph, some segments may not be aligned making ti difficult to compare their attributes. By allowing different sengments to be aligned they can be more easilly compared.

### Changing encoding
A system called datavoyager can be used to change the encoding of a chart completely. This is a incredibly powerful and flexible approach that basically allows the user to design the visualization themselves. However, they would need to have some knowledge of data visualization to get the most out of this system.

### Reducing cognitive load with animated transitions.
Changes in data can make individual elements difficult to keep track of. Animated transitions between states can make these things easier to keep track of, reducing cognitive load

### Selection
Input considerations:
• What are actions to select/deselect?
• How mnay objects can be selected at once?
• Adding to selectiong vs replacing the selection
• Can the selection be empty?
• Are secondary targets required?
• Is selection direction constrained?
• Is selection continuous or discrete?

Feedback considerations:
• Showing the user selected items with visual encoding. However, when these attributes are used to show selection they cannot also be used for the visualization itself.
• Intermediate feedback is needed for the selection to feel responsive. For instance, drawing a rectangle to show a region the mouse has been dragged over.

### Viewpoint navigation
This is allowing the user to move their view of the data. For instance, in a 2d visualization, panning and scrolling around the data. In 3d this would usually include rotating the data.

Considerations:
• What are the users actions that control the viewpoint? If the user also interacts with the data directly, these methods of interaction cannot be used simultaneously.
• What are the directions that the user can navigate? Can the user move continuously or only in discrete steps?

One example of this is common in journalism where the user navigates through visualization by scrolling up/down webpages. The scrolling may modify some visualization by showing the same data across different years as you move. This technique is called Scrollytelling

Pros:
• Familiar, intuitive
• Constrained to up/down, which prevents confusion in possible actions.

Cons:
• It is not always visible that scrolling is needed.
• Scrolling can lead to unexpected behaviour - the user may expect the viewpoint to move rather than the visualization to update
• Scrolling is a continuous control, which is being used for discrete steps of visualization

#### Zoom
There are two types of zoom:

•Geometric zooming
This is moving the viewpoint closer to the same visualization.

•Semantic zooming
This changes the data represented on the visualization at different scales

An example of this is in the lecture recording.

Unconstrained navigation is easy to implement, but hard to control

Constrained navigation follows a computed trajectory, and is typically animated. This is harder to implement.

#### Navigation absed on attributes
•Slice: Show only items with attbibutes matching specific values

•Cut: Show only items with attributes on and beyond a specific slice

•Project: Change the mathematical mapping between the virtual coordinates and screen coordinates. Map projection counts towards this. Also perspective vs oblique projection.